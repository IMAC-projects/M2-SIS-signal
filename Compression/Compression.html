
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Compression &#8212; M2 Signal classes</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TP 1: Analyse en fréquence de signaux sonores." href="../TD/TD1/TP1%20-%20EEA%20-%20Exercices.html" />
    <link rel="prev" title="Filtre" href="../Filtrage/Filtre.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">M2 Signal classes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Introduction/Introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Fourier
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Transform%C3%A9e%20de%20Fourier/Transform%C3%A9e%20de%20Fourier.html">
   Transformée de Fourier
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Filtrage
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Filtrage/Filtre.html">
   Filtre
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Compression
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Compression
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  TD
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD1/TP1%20-%20EEA%20-%20Exercices.html">
   TP 1: Analyse en fréquence de signaux sonores.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD2/TP2%20-%20FFT%20-%20Exercices.html">
   TP2 : FFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD3/TP3%20-%20Compression%20Shannon-Huffman-Exercises.html">
   TP3 : Compression Shannon-Huffman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD4/TP4%20-%20Spectral%20Analysis%20and%20Filtering-Exercise.html">
   1. STFT  (Short Time Fourier Transform) and source separation.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD4/TP4%20-%20Spectral%20Analysis%20and%20Filtering-Exercise.html#the-goal-of-this-part-is-to-explore-implementations-of-a-fir-or-an-iir">
   2. The goal of this part is to explore implementations of a FIR or an IIR.
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Compression/Compression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/IMAC-projects/M2-SIS-signal"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/IMAC-projects/M2-SIS-signal/issues/new?title=Issue%20on%20page%20%2FCompression/Compression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-de-compression">
   Types de compression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#taux-de-compression">
   Taux de compression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entropie-de-shannon">
   Entropie de Shannon
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definition">
     Définition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretation">
     Interprétation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exemple">
     Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#codage-de-huffman">
   Codage de Huffman
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#code-prefixe">
     Code Préfixe
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principe">
     Principe
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inegalite-de-kraft">
     Inégalité de Kraft
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#theoreme-de-kraft-mcmillan">
     Théorème de Kraft-McMillan
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#longueur-moyenne">
     Longueur moyenne
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limitations-du-codage-de-huffman">
     Limitations du codage de Huffman
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#theoreme-de-shannon">
       Théorème de Shannon
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#codage-rle">
   Codage RLE
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cas-du-jpeg">
   Cas du JPEG
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformation-espace-de-couleurs">
     Transformation : espace de couleurs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sous-echantillonnage-de-la-chrominance">
     Sous-échantillonnage de la chrominance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#passage-en-frequence-transformation-en-cosinus-discretes">
     Passage en fréquence : Transformation en cosinus discrètes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantification">
     Quantification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodage-codage-rle-et-codage-de-huffman">
     Encodage - codage RLE et codage de Huffman
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="compression">
<h1>Compression<a class="headerlink" href="#compression" title="Permalink to this headline">¶</a></h1>
<p>La <strong>compression de données</strong> est l’opération consistant à <strong>transformer</strong> une donnée A en une autre B pouvant <strong>restituer</strong> les mêmes informations, ou des informations <em>“proches”</em>, en utilisant un algorithme de <em>décompression</em>.</p>
<p>C’est une opération dite de <strong>codage</strong> qui change la représentation des données visant à en <strong>diminuer</strong> la taille (de stockage) de celles-ci au prix d’un travail de compression (et de décompression pour la restitution des données).</p>
<div class="section" id="types-de-compression">
<h2>Types de compression<a class="headerlink" href="#types-de-compression" title="Permalink to this headline">¶</a></h2>
<p>Il existe deux types de compression de données:</p>
<ul>
<li><p>La compression <strong>sans perte</strong> restituant après décompression un signal (données) strictement identique à l’original avant compression.
On peut exploiter par exemple la redondance des données ou des a priori sur la source de données.
(<strong>Codage RLE,</strong> <strong>codage de Huffman</strong>, <strong>codage LZW</strong> …)</p></li>
<li><p>A l’inverse, la compression <strong>avec perte</strong> restituant un signal différent, mais relativement <em>“proche”</em> du signal d’origine, mais permet une compression plus importante. On considère généralement la différence entre les deux signaux comme négligeable (non perceptible) et étant une perte acceptable dans certains cas pour que la source de données reste compréhensible/perceptible.
On peut par exemple exploiter la perception humaine pour définir l’information négligeable (comme les hautes fréquences d’une image par exemple).</p>
<p>(<strong>sous échantillonnage</strong>, <strong>Codage par DTC</strong>, <strong>codage par ondelettes</strong> …)</p>
</li>
</ul>
</div>
<div class="section" id="taux-de-compression">
<h2>Taux de compression<a class="headerlink" href="#taux-de-compression" title="Permalink to this headline">¶</a></h2>
<p>Le taux de compression que l’on peut noter <span class="math notranslate nohighlight">\(\tau\)</span> est relié au rapport entre la taille <span class="math notranslate nohighlight">\(b\)</span> du fichier compressé <span class="math notranslate nohighlight">\(B\)</span> et la taille <span class="math notranslate nohighlight">\(a\)</span> du fichier original <span class="math notranslate nohighlight">\(A\)</span>. Le taux de compression est généralement exprimé en pourcentage et est défini par :</p>
<div class="math notranslate nohighlight">
\[
\tau = 1 - (b/a)
\]</div>
<p><strong>Exemple :</strong> <span class="math notranslate nohighlight">\(a\)</span> = 550 Mo,  <span class="math notranslate nohighlight">\(b\)</span>=250 Mo , <span class="math notranslate nohighlight">\(\tau = 1 - (250/550) = 54\%\)</span></p>
<p>L’algorithme utilisé cherche généralement à obtenir un taux de compression inférieur à 1.</p>
</div>
<div class="section" id="entropie-de-shannon">
<h2>Entropie de Shannon<a class="headerlink" href="#entropie-de-shannon" title="Permalink to this headline">¶</a></h2>
<p>L’<strong>entropie de Shannon</strong>, crée par Claude Shannon, est une fonction mathématique qui permet de quantifier la quantité d’information contenue par une source d’information. Cette source peut être un texte écrit dans une langue donnée, un signal électrique ou encore un fichier informatique quelconque.</p>
<p>Autrement dit, l’entropie de Shannon indique la <strong>quantité d’information nécessaire</strong> pour que l’on puisse déterminer sans ambiguïté ce que l’on perçoit d’une source de données.
En particulier, plus la source est redondante, moins elle contient d’information. Par exemple, si une source envoie toujours le même symbole, par exemple la lettre ‘a’, alors son entropie est <em>nulle</em>, c’est-à-dire minimale, car l’on peut identifier sans aucune connaissance et sans ambiguïté le prochain symbole émis par la source. En l’absence de contraintes particulières, l’entropie est maximale pour une source dont tous les symboles sont équiprobables.</p>
<div class="section" id="definition">
<h3>Définition<a class="headerlink" href="#definition" title="Permalink to this headline">¶</a></h3>
<p>Pour une source, qui est une variable aléatoire discrète <span class="math notranslate nohighlight">\(X\)</span> comportant <span class="math notranslate nohighlight">\(N\)</span> symboles distincts, chaque symbole <span class="math notranslate nohighlight">\(x_i\)</span> ayant une probabilité <span class="math notranslate nohighlight">\(P_i\)</span> d’apparaître. Les symboles représentent les réalisations possibles de la variable aléatoire <span class="math notranslate nohighlight">\(X\)</span>.
L’<strong>entropie</strong> <span class="math notranslate nohighlight">\(H\)</span> de la source <span class="math notranslate nohighlight">\(X\)</span> est définie comme :</p>
<div class="math notranslate nohighlight">
\[
H_b(X) = -\mathbb{E}[log_b(P(X))] = -\sum_{i=1}^N P_i.log_b(P_i)
\]</div>
<p>Où <span class="math notranslate nohighlight">\(\mathbb{E}\)</span> désigne l’espérance mathématique et <span class="math notranslate nohighlight">\(log_b\)</span> le logarithme en base <em>b</em>.
On utilise en général un logarithme à base 2, car l’entropie s’exprime alors en nombre de bits par symbole. Dans ce cas, on peut interpréter <span class="math notranslate nohighlight">\(H(X)\)</span> comme le nombre de questions à réponse binaire que l’on doit poser en moyenne à la source, ou la quantité d’information en bits que la source doit fournir au récepteur pour que ce dernier puisse déterminer sans ambiguïté la valeur de <span class="math notranslate nohighlight">\(X\)</span>.</p>
<div class="math notranslate nohighlight">
\[
H(X) = H_2(X) = -\sum_{i=1}^N P_i.log_2(P_i)
\]</div>
</div>
<div class="section" id="interpretation">
<h3>Interprétation<a class="headerlink" href="#interpretation" title="Permalink to this headline">¶</a></h3>
<p>Dans le cas où l’on dispose d’un nombre <span class="math notranslate nohighlight">\(N\)</span> de symboles de la forme <span class="math notranslate nohighlight">\(N= 2^n\)</span> avec <span class="math notranslate nohighlight">\(n\)</span> entier et où les <span class="math notranslate nohighlight">\(N\)</span> symboles sont équiprobables, il suffit de <span class="math notranslate nohighlight">\(n\)</span> questions, en procédant par dichotomie, pour déterminer le symbole envoyé par la source. Dans ce cas, la quantité d’information contenue par le symbole est exactement <span class="math notranslate nohighlight">\(n = log_2(N)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(X) =&amp; -\sum_{i=1}^N P_i.log_2(P_i) \\
	 =&amp; -\sum_{i=1}^N \frac{1}{N}.log_2(\frac{1}{N}) \\
	 =&amp; -\frac{1}{N} \sum_{i=1}^N log_2(\frac{1}{N}) \\
	 =&amp; -\frac{1}{N} * N.log_2(\frac{1}{2^n}) \\
	 =&amp;\quad log_2(2^n) = n\\
\end{align}
\end{split}\]</div>
<p>De manière plus générale, il est naturel de conserver cette formule dans le cas où <span class="math notranslate nohighlight">\(N\)</span> n’est pas une puissance de 2. Par exemple, si les symboles sont les lettres de l’alphabet et que l’on les considère toutes équiprobables, alors l’information contenue par un symbole est <span class="math notranslate nohighlight">\(log_2(26) \approx 4.7\)</span> .
Cette valeur est une valeur intermédiaire entre 4 bits (permettant de coder 16 symboles) et 5 bits (qui permet d’en coder 32).</p>
</div>
<div class="section" id="exemple">
<h3>Exemple<a class="headerlink" href="#exemple" title="Permalink to this headline">¶</a></h3>
<p>Considérons une urne contenant des boules de 4 couleurs différentes: rouge, bleue, jaune et vert, toutes équiprobables.
On tire une boule au hasard et il s’agit d’en identifier la couleur. Comme aucun tirage n’est privilégié, l’entropie est ici maximale égale à  <span class="math notranslate nohighlight">\(log_2(4)=2\)</span>.
Si on convient que les couleurs sont codées respectivement <span class="math notranslate nohighlight">\(00\)</span>, <span class="math notranslate nohighlight">\(01\)</span>, <span class="math notranslate nohighlight">\(10\)</span>, <span class="math notranslate nohighlight">\(11\)</span>, l’information contenue dans le tirage correspond effectivement à 2 bits.</p>
<p>Mais si une certaine couleur est plus représentée que les autres, alors l’entropie est légèrement réduite. Supposons par exemple que l’urne contienne 4 boules rouges, 2 bleues, 1 jaune et 1 verte.</p>
<p>On peut calculer l’entropie de la manière suivante:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H(X) =&amp; -\sum_{i=1}^N P_i.log_2(P_i) \\
	 =&amp; -\left( \frac{4}{8}.log_2(\frac{4}{8}) + \frac{2}{8}.log_2(\frac{2}{8}) + \frac{1}{8}.log_2(\frac{2}{8}) + \frac{2}{8}.log_2(\frac{1}{8})\right) \\
	 =&amp; -\left( \frac{log_2(\frac{1}{2})}{2} + \frac{log_2(\frac{1}{4})}{4} + \frac{log_2(\frac{1}{8})}{8} + \frac{log_2(\frac{1}{8})}{8}\right) \\
	 =&amp; \quad \frac{log_2(2)}{2} + \frac{log_2(4)}{4} + \frac{log_2(8)}{8} + \frac{log_2(8)}{8} \\
	 =&amp; \quad \frac{1}{2} + \frac{2}{4} + \frac{3}{8} + \frac{3}{8} \\
	 =&amp; \quad \frac{7}{4} = 1.75
\end{align}
\end{split}\]</div>
<p>Si les couleurs sont codées respectivement <span class="math notranslate nohighlight">\(0\)</span> pour le rouge, <span class="math notranslate nohighlight">\(10\)</span> pour le bleu, <span class="math notranslate nohighlight">\(110\)</span> pour le jaune et <span class="math notranslate nohighlight">\(111\)</span> pour le vert, alors l’information sur la couleur tirée occupe 1 bit une fois sur deux, 2 bits une fois sur quatre et 3 bits une fois sur quatre, soit en moyenne 7/4 bits, correspondant à l’entropie calculée.</p>
</div>
</div>
<div class="section" id="codage-de-huffman">
<h2>Codage de Huffman<a class="headerlink" href="#codage-de-huffman" title="Permalink to this headline">¶</a></h2>
<p>Le <strong>codage de Huffman</strong> est un algorithme de compression de données <strong>sans perte</strong>. Il consiste à utiliser un code à longueur variable pour représenter un symbole d’une source de données en ayant une connaissance préalable (ou une estimation) des probabilités d’apparition des symboles de cette source. Un code court étant associé aux symboles les plus fréquents.</p>
<p>Un code de Huffman est optimal au sens de la plus courte longueur pour un codage par symbole et une distribution de probabilité connue. Des méthodes plus complexes réalisant une modélisation probabiliste de la source permettent d’obtenir de meilleurs ratios de compression.</p>
<div class="section" id="code-prefixe">
<h3>Code Préfixe<a class="headerlink" href="#code-prefixe" title="Permalink to this headline">¶</a></h3>
<p>Soit <span class="math notranslate nohighlight">\(C\)</span> un code.
Il est dit <strong>code préfixe</strong> si aucun mot du code n’a pour préfixe un autre mot du code ou autrement dit, si aucun mot de ce code n’est le début d’un autre mot de code.</p>
<p>Contre exemple :
Soit <span class="math notranslate nohighlight">\(X = \{a, b, c, d\}\)</span> un ensemble de symbole.
On considère le code <span class="math notranslate nohighlight">\(C\)</span> suivant  (<span class="math notranslate nohighlight">\(x \in X\)</span>) :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
C(x) = \left\{
\begin{array}{rl}
01 &amp;:\; x = a  \\ 
010 &amp;:\; x = b \\
111 &amp;:\; x = c \\
11 &amp;:\; x = d
\end{array}
\right.
\end{split}\]</div>
<p>Le codage <span class="math notranslate nohighlight">\(010111\)</span> peut alors s’interpréter de deux façons : <span class="math notranslate nohighlight">\(a\;a\;d\)</span> ou <span class="math notranslate nohighlight">\(b\;c\)</span>.
Ce code <strong>possède plusieurs interprétations</strong>, il n’est pas préfixe, car le code du symbole <span class="math notranslate nohighlight">\(d\)</span> est le début du code du symbole de <span class="math notranslate nohighlight">\(c\)</span>.</p>
<p><strong>Remarque :</strong> À un code préfixe <span class="math notranslate nohighlight">\(C\)</span> nous pouvons toujours associer un arbre binaire, où tous les mots de code se situent sur les feuilles de l’arbre.
<span class="math notranslate nohighlight">\(C(X ) = \{000, 100, 101, 0010, 0101, 1100, 1111, 00110, 00111, 01000, 01001, 11010, 11011, 11100, 11101\}\)</span></p>
<p><img alt="image-20201031141224315" src="../_images/ArbrePrefixe.png" /></p>
<p><strong>Remarques:</strong></p>
<ul class="simple">
<li><p>Autre mot de code ne peut être trouvé dans les sous-arbres qui ont comme racine un mot de code (les branches en pointillé dans la Figure).</p></li>
<li><p>Soit <span class="math notranslate nohighlight">\(n\)</span> niveau n de l’arbre binaire. Le nombre maximal de mots de code de longueur <span class="math notranslate nohighlight">\(n\)</span> est <span class="math notranslate nohighlight">\(2^n\)</span>.</p></li>
<li><p>Le nombre de descendants au niveau <span class="math notranslate nohighlight">\(n\)</span> d’un nœud du niveau <span class="math notranslate nohighlight">\(m\)</span> tel que <span class="math notranslate nohighlight">\(m ≤ n\)</span> est <span class="math notranslate nohighlight">\(2n−m \)</span>.</p></li>
</ul>
</div>
<div class="section" id="principe">
<h3>Principe<a class="headerlink" href="#principe" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>TODO: expliquer la méthode, probabilités, construction de l’arbre et décodage</p>
</div></blockquote>
</div>
<div class="section" id="inegalite-de-kraft">
<h3>Inégalité de Kraft<a class="headerlink" href="#inegalite-de-kraft" title="Permalink to this headline">¶</a></h3>
<p>Soient <span class="math notranslate nohighlight">\(X = \{x_0, x_1, \dots, x_n \}\)</span> une source et <span class="math notranslate nohighlight">\(C\)</span> un code uniquement décodable (préfixe) de <span class="math notranslate nohighlight">\(X\)</span> sur un alphabet de taille <span class="math notranslate nohighlight">\(\tau\)</span>.  on note <span class="math notranslate nohighlight">\(l_i = l(C(x_i))\)</span> la longueur du code représentant le symbole <span class="math notranslate nohighlight">\(x_i\)</span> dans le codage <span class="math notranslate nohighlight">\(C\)</span>. Alors on a :</p>
<div class="math notranslate nohighlight">
\[
\sum_{x \in X} \tau^{- l(C(x))} \leq 1
\]</div>
<p>De manière moins générique, pour un codage <span class="math notranslate nohighlight">\(C\)</span> binaire (d’alphabet de taille <span class="math notranslate nohighlight">\(\tau = 2\)</span>) alors on a :</p>
<div class="math notranslate nohighlight">
\[
\sum_{x \in X} 2^{-l(C(x))} = \sum_{i=1}^n 2^{-l_i} \leq 1
\]</div>
<p><strong><font color=red>Demonstration : </font></strong> ( <span class="math notranslate nohighlight">\(\tau = 2\)</span> pour plus de clarté)</p>
<blockquote>
<div><p>La démonstration est faite en considérant <span class="math notranslate nohighlight">\(\tau = 2\)</span> par simplicité mais peut se généraliser facilement.</p>
</div></blockquote>
<p><img alt="image-20201031141224315" src="../_images/ArbrePrefixe.png" /></p>
<p>Si le code préfixe, on peut faire une démonstration simple par analogie avec son graphe.
Notons la taille maximum d’un mot dans notre codage <span class="math notranslate nohighlight">\(C\)</span> :  <span class="math notranslate nohighlight">\(l_{max} = Max(l_i)_{i \in [\hspace{-0.1em}[ 1, n ]\hspace{-0.1em}]}\)</span><br />
(dans le graphe ci-dessus <span class="math notranslate nohighlight">\(l_{max} = 5\)</span>)
Comme ce code est préfixe, il existe des zones interdites pour placer les différents symboles comme expliqué précédemment.</p>
<p>Si on se place sur une feuille quelconque de l’arbre représentant notre code préfixe, alors il y a <span class="math notranslate nohighlight">\(2^{(l_{max}-l_i)}\)</span> descendants inaccessibles entre ce nœud et le niveau max. L’arbre complet de <span class="math notranslate nohighlight">\(l_{max}\)</span> niveaux  possède  <span class="math notranslate nohighlight">\(2^{l_{max}}\)</span> feuilles.  La somme des descendants inaccessibles doit donc naturellement être inférieure au nombre maximal de descendants.</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n 2^{l_{max}- l_i} \leq 2^{l_{max}}
\]</div>
<p>ce qui donne naturellement après simplification:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n 2^{-l_i} \leq 1
\]</div>
<blockquote>
<div><p>Remarque :
Le codage est optimal lorsque qu’il y a égalité</p>
</div></blockquote>
<p><em>Bonus :</em> La réciproque est vrai !</p>
</div>
<div class="section" id="theoreme-de-kraft-mcmillan">
<h3>Théorème de Kraft-McMillan<a class="headerlink" href="#theoreme-de-kraft-mcmillan" title="Permalink to this headline">¶</a></h3>
<p>Soit <span class="math notranslate nohighlight">\({n(x) &gt; 0, x \in X }\)</span>, des entiers positifs qui vérifient l’inégalité de Kraft-McMillan):</p>
<div class="math notranslate nohighlight">
\[
\sum_{x \in X} 2^{- n(x)} \leq 1
\]</div>
<p>Alors, <em>il existe un code de préfixe</em> <span class="math notranslate nohighlight">\(C\)</span> avec une longueur <span class="math notranslate nohighlight">\(l(x) = n(x)\)</span> (qui est donc nécessairement uniquement décodable.)</p>
</div>
<div class="section" id="longueur-moyenne">
<h3>Longueur moyenne<a class="headerlink" href="#longueur-moyenne" title="Permalink to this headline">¶</a></h3>
<p>Soient <span class="math notranslate nohighlight">\(X = \{x_0, x_1, \dots, x_n \}\)</span> une source, <span class="math notranslate nohighlight">\(p_i = p(x_i) = \mathbb{P}(X = x_i)\)</span> la probabilité d’apparition du caractère <span class="math notranslate nohighlight">\(x_i\)</span> et <span class="math notranslate nohighlight">\(C\)</span> un codage de Huffman associé à <span class="math notranslate nohighlight">\(X\)</span>.
Il est possible d’exprimer la longueur moyenne de ce codage via la formule:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{L}(C) = \sum_{x\in X} p_i.l(C(x)) = \sum_{x\in X} p_i.l_i
\]</div>
</div>
<div class="section" id="limitations-du-codage-de-huffman">
<h3>Limitations du codage de Huffman<a class="headerlink" href="#limitations-du-codage-de-huffman" title="Permalink to this headline">¶</a></h3>
<div class="section" id="theoreme-de-shannon">
<h4>Théorème de Shannon<a class="headerlink" href="#theoreme-de-shannon" title="Permalink to this headline">¶</a></h4>
<p>La longueur moyenne de tout code préfixe <span class="math notranslate nohighlight">\(\mathbb{L}(C)\)</span> d’alphabet de taille <span class="math notranslate nohighlight">\(\tau\)</span> pour la source <span class="math notranslate nohighlight">\(X\)</span> est supérieure ou égale à l’entropie de la source:</p>
<div class="math notranslate nohighlight">
\[
H_\tau(X) \leq \mathbb{L}(C)
\]</div>
<p>De plus, il est possible de montrer qu’il existe un code préfixe <span class="math notranslate nohighlight">\(C\)</span> qui code <span class="math notranslate nohighlight">\(X\)</span> avec une longueur moyenne à moins d’un bit de son entropie :</p>
<div class="math notranslate nohighlight">
\[
\mathbb{L}(C) \leq H_\tau(X) +1
\]</div>
<p>Pour résumer, On peut montrer que pour une source <span class="math notranslate nohighlight">\(X\)</span> d’entropie de Shannon <span class="math notranslate nohighlight">\(H(X)\)</span> la longueur moyenne <span class="math notranslate nohighlight">\(\mathbb{L}(C)\)</span> d’un mot de code obtenu par codage de Huffman <span class="math notranslate nohighlight">\(C\)</span> de <span class="math notranslate nohighlight">\(X\)</span> vérifie:</p>
<div class="math notranslate nohighlight">
\[
H(X) \leq \mathbb{L}(C) \leq H(X) +1
\]</div>
<hr class="docutils" />
<p><strong><font color=red>Demonstration <span class="math notranslate nohighlight">\(H_\tau(X) \leq \mathbb{L}(C)\)</span>: </font></strong> ( <span class="math notranslate nohighlight">\(\tau = 2\)</span> pour plus de clarté)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{L}(C) - H(X) =&amp; \sum_{i=1}^n p_i.l_i + \sum_{i=1}^n p_i.log_2(p_i) \\
=&amp; \sum_{i=1}^n p_i.-1.(-l_i) + \sum_{i=1}^n p_i.log_2(p_i) \\
=&amp; -\sum_{i=1}^n p_i.log_2(2^{-l_i}) + \sum_{i=1}^n p_i.log_2(p_i) \\
\end{align}
\end{split}\]</div>
<p>Posons une nouvelle distribution de probabilité normée (de somme égale à 1) de <span class="math notranslate nohighlight">\(X\)</span> :</p>
<div class="math notranslate nohighlight">
\[
q(x_i) = q_i = \frac{2^{-l(C(x))}}{\sum_{i=1}^n2^{-l(C(x))}}= \frac{2^{-l_i}}{\sum_{i=1}^n2^{-l_i}} = \frac{2^{-l_i}}{S}
\]</div>
<p>où on pose <span class="math notranslate nohighlight">\(S = \sum_{i=1}^n2^{-l_i}\)</span></p>
<p>ainsi on a :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{L}(C) - H(X) =&amp; -\sum_{i=1}^n p_i.log_2(S.q_i) + \sum_{i=1}^n p_i.log_2(p_i) \\
=&amp; -\sum_{i=1}^n p_i.(log_2(S) + log_2(q_i))+ \sum_{i=1}^n p_i.log_2(p_i) \\
=&amp; -\sum_{i=1}^n p_i.log_2(S) -\sum_{i=1}^n p_i.log_2(q_i) + \sum_{i=1}^n p_i.log_2(p_i) \\
=&amp; -log_2(S)\sum_{i=1}^n p_i + \sum_{i=1}^n p_i.(log_2(p_i)- log_2(q_i)) \\
=&amp; -log_2(S) + \sum_{i=1}^n p_i.log_2(\frac{p_i}{q_i}) \\
\end{align}
\end{split}\]</div>
<p>Remarquons que, comme <span class="math notranslate nohighlight">\(S = \sum_{i=1}^n2^{-l_i}\)</span>, <span class="math notranslate nohighlight">\(S\)</span> est une grandeur inférieure à 1 étant donné l’inégalité de Kraft. Le logarithme de <span class="math notranslate nohighlight">\(S\)</span> est donc négatif, précédé d’un moins, i.e : <span class="math notranslate nohighlight">\(-log_2(S) \geq 0\)</span>.</p>
<p>Le terme de droite correspond à la définition d’entropie relative :</p>
<div class="math notranslate nohighlight">
\[
D(p||q) = \sum_{i=1}^n p_i.log_2(\frac{p_i}{q_i})
\]</div>
<p>Il est possible de montrer que l’entropie relative est une grandeur positive.</p>
<blockquote>
<div><p>Inégalité de Jensen</p>
<p>Soit <span class="math notranslate nohighlight">\(f\)</span> une fonction convexe, f <span class="math notranslate nohighlight">\(\mathbb{R}^n \to \mathbb{R}\)</span>  et <span class="math notranslate nohighlight">\(X\)</span> un vecteur aléatoire <span class="math notranslate nohighlight">\(X \in \mathbb{R}^n\)</span> avec une loi de probabilité <span class="math notranslate nohighlight">\(p\)</span> alors :
$$</p>
<p>\mathbb{E}_p[f(x)] \geq f(\mathbb{E}_p[x])
$$</p>
<hr class="docutils" />
<div class="math notranslate nohighlight">
\[
&gt; D(p||q) = \sum_{i=1}^n p_i.log_2(\frac{p_i}{q_i}) = \sum_{i=1}^n p_i.-log_2(\frac{q_i}{p_i}) = \mathbb{E}_p[-log_2(\frac{q(x)}{p(x)})]
&gt; \]</div>
<p>Comme <span class="math notranslate nohighlight">\(-log(.)\)</span> est convexe,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
&gt; \begin{align}
&gt; D(p||q) \geq&amp; -log_2(\mathbb{E}_p[\frac{q(x)}{p(x)}]) \\
&gt; \geq&amp; -log_2(\sum_{i=1}^n p_i.\frac{q_i}{p_i}) \\
&gt; \geq&amp; -log_2(\sum_{i=1}^n q_i) \\
&gt; \geq&amp; -log_2(1) = 0 \\
&gt; \end{align}
&gt; \end{split}\]</div>
<p>Finalement on a bien</p>
<div class="math notranslate nohighlight">
\[
&gt; D(p||q) \geq 0
&gt; \]</div>
<p>Les deux termes sont alors positifs et on a donc :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
&gt; \mathbb{L}(C) - H(X) \ge 0 \\
&gt; \mathbb{L}(C) \geq H(X)
&gt; \end{split}\]</div>
</div></blockquote>
<hr class="docutils" />
<p><strong><font color=red>Démonstration <span class="math notranslate nohighlight">\(\mathbb{L}(C) \leq H_\tau(X) +1\)</span>: </font></strong> ( <span class="math notranslate nohighlight">\(\tau = 2\)</span> pour plus de clarté)</p>
<p>Soient <span class="math notranslate nohighlight">\(X = \{x_0, x_1, \dots, x_n \}\)</span> une source, <span class="math notranslate nohighlight">\(p_i = \mathbb{P}(X = x_i)\)</span> la probabilité d’apparition du caractère <span class="math notranslate nohighlight">\(x_i\)</span> .</p>
<p>Commençons par démontrer qu’il existe un code dont les longueurs <span class="math notranslate nohighlight">\(l_i\)</span> sont égales à :</p>
<div class="math notranslate nohighlight">
\[
l_i = l(C(x_i)) = \lceil log_2(\frac{1}{pi})\rceil
\]</div>
<p>Pour <span class="math notranslate nohighlight">\(x\geq 0\)</span> ,on sait que <span class="math notranslate nohighlight">\(x \leq \lceil x\rceil \leq x + 1\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{ccc}
x &amp;\leq&amp; \lceil x\rceil \\
-\lceil x\rceil &amp;\leq&amp; -x \\
\end{array}
\end{split}\]</div>
<p>Comme  <span class="math notranslate nohighlight">\(x \geq 0\)</span> on peut élever à la puissance 2</p>
<div class="math notranslate nohighlight">
\[
2^{-\lceil x\rceil} \leq\; 2^{-x}
\]</div>
<p>En remplaçant  <span class="math notranslate nohighlight">\(x\)</span> par <span class="math notranslate nohighlight">\(log_2(\frac{1}{p_i})\)</span> on obtient:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n 2^{-\lceil log_2(\frac{1}{p_i}) \rceil} \leq \sum_{i=1}^n 2^{- log_2(\frac{1}{p_i})} = \sum_{i=1}^n p_i = 1
\]</div>
<p>Alors d’après le Théorème de Kraft-McMillan il existe un code <span class="math notranslate nohighlight">\(C\)</span> préfixe dont les longueurs sont égales à <span class="math notranslate nohighlight">\(l_i = l(C(x_i)) = \lceil log_2(\frac{1}{pi})\rceil\)</span></p>
<p>Calculons la longueur moyenne de ce code :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{L}(C) =&amp; \sum_{i\in n} p_i.l_i \\
=&amp; \sum_{i\in n} p_i\lceil log_2(\frac{1}{pi})\rceil \\
\leq&amp; \sum_{i\in n} p_i(log_2(\frac{1}{pi})+1) \\
\leq&amp; -\sum_{i\in n} p_i.log_2(p_i) + \sum_{i\in n}p_i \\
\leq&amp; H(X) + 1 \\
\end{align}
\end{split}\]</div>
</div>
</div>
</div>
<div class="section" id="codage-rle">
<h2>Codage RLE<a class="headerlink" href="#codage-rle" title="Permalink to this headline">¶</a></h2>
<p>Le <strong>run-length encoding</strong>, est un algorithme de compression de données sans perte en informatique.</p>
<p>L’idée général est de considérer, pour une source de données <span class="math notranslate nohighlight">\(X\)</span>, les répétitions successives de ses symboles. Cela consiste à remplacer les suites de caractères identiques par ce caractère suivi du nombre de répétition de celui-ci. Par exemple, pour la suite de suivante :</p>
<blockquote>
<div><p>A C F X X X X C C U U U D C C C C C</p>
</div></blockquote>
<p>Le codage <strong>RLE</strong> deviens :</p>
<blockquote>
<div><p>1 A 1 C 1 F 4 X 2 C 3 U 1 D 4 C</p>
</div></blockquote>
<p>Cela peut s’écrire plus efficacement directement avec le symbole lorsque celui-ci n’est présent qu’une fois (on obtient alors toujours au maximum la même taille) :</p>
<blockquote>
<div><p>A C F 4 X 2 C 3 U D 4 C</p>
</div></blockquote>
<p>Car cela peut mener à une suite de symbole plus longue dans le cas contraire :</p>
<blockquote>
<div><p>WBWBWBWBWB</p>
</div></blockquote>
<p>devient sans cette astuce :</p>
<blockquote>
<div><p>1W1B1W1B1W1B1W1B1W1B</p>
</div></blockquote>
</div>
<div class="section" id="cas-du-jpeg">
<h2>Cas du JPEG<a class="headerlink" href="#cas-du-jpeg" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>TODO</p>
</div></blockquote>
<div class="section" id="transformation-espace-de-couleurs">
<h3>Transformation : espace de couleurs<a class="headerlink" href="#transformation-espace-de-couleurs" title="Permalink to this headline">¶</a></h3>
<p>Il existe plusieurs manières de représenter les couleurs d’une image, soit par les trois composantes <em><strong>Rouge, Vert et Bleu</strong></em> de la synthèse additive d’une couleur (représentation RGB), soit par une représentation circulaire des couleurs où l’on représente trois composantes de <em><strong>teinte</strong></em>, de <em><strong>saturation</strong></em>, et de <em><strong>luminance</strong></em> d’une couleur (représentation TSL). Enfin il est également possible de représenter d’abord la luminance (signal en niveau de gris) et par la suite les deux chrominances, qui représentent chacune une différence de couleur par rapport à la luminance respectivement <strong>U</strong> ou <strong>Cb</strong> pour la différence avec le bleu (B-Y) et <strong>Y</strong> ou Cr pour la différence avec rouge (R - Y). Il est donc possible de passer de RGB a YUV (<strong>YCbCr</strong>) via les calculs suivants:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
	\begin{bmatrix}
	mathrm {Y} \\
	mathrm {U} \\
	mathrm {V}
	\end{bmatrix}
	=
	\begin{bmatrix}
	0,299 &amp; 0,587 &amp; 0,114\\
	-0,14713 &amp; -0,28886 &amp; 0,436\\
	0,615 &amp; -0,51498 &amp; -0,10001
	\end{bmatrix}
	.
	\begin{bmatrix}
	mathrm {R} \\
	mathrm {G} \\
	mathrm {B}
	\end{bmatrix}
\end{equation}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
	\begin{bmatrix}
	mathrm {R} \\
	mathrm {G} \\
	mathrm {B}
	\end{bmatrix}
	=
	\begin{bmatrix}
	1 &amp; 0 &amp; 1,13983 \\
	1 &amp; -0,39465 &amp; -0,58060  \\
	1 &amp; 2,03211 &amp; 0
	\end{bmatrix}
	.
	\begin{bmatrix}
	mathrm {Y} \\
	mathrm {U} \\
	mathrm {V}
	\end{bmatrix}
\end{equation}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
1 &amp; 0 &amp; 1,13983 \\
1 &amp; -0,39465 &amp; -0,58060  \\
1 &amp; 2,03211 &amp; 0
\end{bmatrix}
\end{split}\]</div>
<p>L’intérêt d’une telle transformation est que la vision humaine présente une <strong>sensibilité moindre</strong> à la couleur qu’à la luminosité. On va donc pouvoir <strong>sous échantillonner</strong> les composantes de chrominance sans affecter fortement la qualité du rendu final de l’image.</p>
</div>
<div class="section" id="sous-echantillonnage-de-la-chrominance">
<h3>Sous-échantillonnage de la chrominance<a class="headerlink" href="#sous-echantillonnage-de-la-chrominance" title="Permalink to this headline">¶</a></h3>
<p>L’œil humain est beaucoup plus sensible aux variations de lumière qu’à celles de couleur. Ainsi afin de pouvoir permettre un meilleur taux de compression, il est possible de <strong>réduire la répétition</strong> entre les informations de couleurs.</p>
<p>On fait donc appel au <strong>sous-échantillonnage de chrominance</strong>. Cela va donc permettre de réduire la résolution spatiale c’est-à-dire réduire la quantité d’information sur une même surface. On peut ainsi se demander comment cela fonctionne.</p>
<p>Le procédé reste relativement simple. En effet il repose sur la <strong>suppression de paires (Cb;Cr)</strong> ou (U;V) de certains pixels de l’image. Toutefois, il est nécessaire de choisir le mode de sous-échantillonnage parmi ceux utilisés en JPEG : le mode 4:2:0, 4:2:2 ou le mode 4:4:4.</p>
<p>Chaque triplet se décompose ainsi en trois nombres (J : a : ​b) correspondant chacun à une information sur le bloc. On considérera ici un bloc comme étant une région de quatre pixels de largeur sur 2 pixels de hauteur.</p>
<p>Le nombre <strong>J</strong> représente le nombre d’échantillons de luminance par ligne ou encore la largeur du bloc pour le traitement de la chrominance. Ici au vue de la définition que nous avons donnée du bloc on peut ici considérer que J vaut 4.</p>
<p>Le nombre <strong>a</strong> représente le nombre d’échantillons de chrominance (Cb, Cr) dans la première ligne tandis que b représente celui de la deuxième ligne.</p>
<p><img alt="Subsampling modes" src="../_images/subSampling.png" /></p>
<p>Ainsi, en s’intéressant de plus près au schéma, on peut voir l’évolution du bloc, selon les différents modes de sous échantillonnage appliqués.</p>
<ul class="simple">
<li><p>On peut donc voir qu’en commençant par la gauche, le premier mode 4:4:4 correspond au mode où aucune altération n’a été réalisée. Nous sommes donc dans le cas de notre image d’origine. Chaque case possède bien une information de luminance (carré gris Y) ainsi que les deux informations de chrominances (triangles bleu Cb et rouge Cr).</p></li>
<li><p>Dans le second mode 4:2:2, les informations de luminances sont conservées, mais on ne conserve que deux couples d’informations de chrominance sur les quatre de chaque ligne. Les deux composantes de chrominance sont donc échantillonnées à la moitié de la fréquence d’échantillonnage de luminance. Les pixels ne contenant pas d’informations de chrominances sont affichés lors du décodage avec une moyenne des valeurs gauche et droite.</p></li>
<li><p>Dans le troisième mode <strong>4:2:0</strong>, seules deux des couples d’informations de chrominances de la première ligne sont conservées. Pour retrouver les informations perdues, on procédera de la même manière que dans le mode précédent en moyennant les valeurs manquantes lors du décodage.</p></li>
<li><p>Le dernier mode <strong>4:1:1</strong> est peu utilisée voire jamais dans le cas du JPEG.</p></li>
</ul>
<p>Grâce à cette méthode, le nombre d’échantillons contenu dans l’image diminuant, le volume de l’image traitée diminue aussi permettant donc d’obtenir une image moins conséquente en terme de taille sans pour autant la dégrader de façon trop visible pour l’œil humain.</p>
</div>
<div class="section" id="passage-en-frequence-transformation-en-cosinus-discretes">
<h3>Passage en fréquence : Transformation en cosinus discrètes<a class="headerlink" href="#passage-en-frequence-transformation-en-cosinus-discretes" title="Permalink to this headline">¶</a></h3>
<p>Jusqu’à présent, on a juste transformé le mode de couleur en YUV ou YCbCr et appliqué un sous-échantillonnage sur les composantes de la chrominance. Nous allons à présent appliquer la DCT à l’image.</p>
<p>Considérons ici par simplicité pour les explications une unique couche, la luminance.</p>
<p>A l’image d’une transformée de Fourier, il est possible d’appliquer une <strong>transformée en cosinus discrète TCD ou DCT</strong> à un signal/image. Cela permet de représenter l’image sous forme de “fréquences”.</p>
<p>La DCT et en particulier la DCT-II est très utilisée en traitement du signal. L’intérêt d’une telle transformation en fréquence se voit particulièrement bien sûr l’image suivante (un échantillon de taille 8x8 de notre image) :</p>
<p><img alt="DCT coefficients" src="../_images/DCTonBlock8x8.png" /></p>
<p>A gauche un bloc de notre image et à droite le calcul des coefficients de la DCT-II . On voit clairement ici que les coefficients de grande importance pour reconstituer l’image se concentrent en haut à gauche (les coefficients dit de <em>basses fréquences</em>).</p>
<p>L’idée de la compression par DCT est de conserver uniquement les quelques coefficients important (basses fréquences) non nuls utiles pour reconstruire la majorité de l’image et annuler les autres petites valeurs par quantification (c’est une opération analogue à l’application d’un filtre passe bas).</p>
<p>La DCT-II s’applique en 2D via la formule suivante : (sur un bloc de taille <span class="math notranslate nohighlight">\(M\times N\)</span>)</p>
<div class="math notranslate nohighlight">
\[
DCT[i, j] = \frac{2}{\sqrt{MN}} C(i)C(j)\sum^{N-1}_{x=0}\sum^{M-1}_{y=0} pixel[x, y].cos(\frac{\pi i}{2N}.(2x+1)).cos(\frac{\pi j}{2M}.(2y+1))
\]</div>
<p>avec :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
C(x) = \left\{
\begin{array}{rl}
\frac{1}{\sqrt{2}} &amp; \text{si } x = 0  \\ 
1 &amp; \text{sinon} \\
\end{array}
\right.
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\frac{2}{\sqrt{MN}}\)</span> , <span class="math notranslate nohighlight">\(C(i)\)</span> et <span class="math notranslate nohighlight">\(C(j)\)</span> sont des facteurs qui permettent de rendre la transformation orthogonale car cette forme normalisée est très utilisée en pratique.</p>
<p>L’application de la DCT est une opération <strong>théoriquement sans perte d’informations</strong> ; les coefficients initiaux peuvent être retrouvés en appliquant la « DCT inverse » au résultat de la DCT. Dans la pratique, une certaine perte d’informations reste cependant possible en raison des erreurs d’arrondis introduites en cours de calcul.</p>
<hr class="docutils" />
<p>À chaque bloc de <span class="math notranslate nohighlight">\(N \times N\)</span> pixels sont ainsi associés <span class="math notranslate nohighlight">\(N \times N\)</span> fréquences.</p>
<p>Celle-ci est appliquée sur les deux axes de l’image 2D, ci-dessous une représentation des différentes fréquences ainsi obtenue sur les deux axes.</p>
<p><img alt="Représentation des fréquences" src="../_images/DCT.jpg" /></p>
</div>
<div class="section" id="quantification">
<h3>Quantification<a class="headerlink" href="#quantification" title="Permalink to this headline">¶</a></h3>
<p>L’œil humain distingue difficilement les zones de hautes fréquences, il est donc envisageable de <strong>réduire l’importance de ces zones de hautes fréquences</strong> sur l’image considérée.</p>
<p>Ainsi cette opération permettra également de réduire la place mémoire nécessaire pour le stockage de l’image en question.</p>
<p>Le principe de la quantification est relativement simple.</p>
<p>Cela repose sur une division de chaque coefficient de la matrice DCT obtenue par une constante afin de réduire le nombre d’entiers utilisés pour chaque valeur. La valeur de la constante va dépendre de l’endroit où se trouve les coefficients et l’on va donc réaliser une division de la matrice obtenue après DCT par une nouvelle matrice dite  <strong>de quantification</strong> .</p>
<p>Les basses fréquences étant représentées par les coefficients situés dans le coin haut gauche de la matrice de coefficients de la DTC et l’œil humain étant plus sensible à ces fréquences-ci, les coefficients de la matrice de quantification seront plus faibles dans cette zone afin de pouvoir mieux <strong>conserver les informations importantes pour notre système visuel</strong>.</p>
<p>Exemple de matrice de quantification :
$<span class="math notranslate nohighlight">\(
\begin{bmatrix}
3&amp;5&amp;7&amp;9&amp;11&amp;13&amp;15&amp;17\\
5&amp;7&amp;9&amp;11&amp;13&amp;15&amp;17&amp;19\\
7&amp;9&amp;11&amp;13&amp;15&amp;17&amp;19&amp;21\\
9&amp;11&amp;13&amp;15&amp;17&amp;19&amp;21&amp;23\\
11&amp;13&amp;15&amp;17&amp;19&amp;21&amp;23&amp;25\\
13&amp;15&amp;17&amp;19&amp;21&amp;23&amp;25&amp;27\\
15&amp;17&amp;19&amp;21&amp;23&amp;25&amp;27&amp;29\\
17&amp;19&amp;21&amp;23&amp;25&amp;27&amp;29&amp;31
\end{bmatrix}
\)</span>$</p>
<blockquote>
<div><p>Les coefficients les plus fort correspondent aux hautes fréquences</p>
</div></blockquote>
<p>Après division, il suffit de prendre l’arrondis des coefficients qui seront pour la plupart nuls. On <strong>élimine ainsi les informations de faible importance</strong> pour notre vision. C’est donc à cette étape-ci qu’il y a <strong>pertes ou destruction d’informations par rapport à l’image originale</strong> et c’est pour cette raison que l’on qualifie la compression JPEG d’irréversible et destructive.</p>
<p>Voilà le résultat de cette étape de quantification : une image complète appliquée par blocs de <span class="math notranslate nohighlight">\(8 \times 8\)</span>
<img alt="blockwise DCT quantization" src="../_images/DCTQuantization.png" /></p>
<p>Et voici un exemple plus spécifiquement sur un bloc particulier avant et après quantification :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
1260&amp;-1&amp;-12&amp;-5&amp;2&amp;-2&amp;-3&amp;1\\
-23&amp;-17&amp;-6&amp;-3&amp;-3&amp;0&amp;0&amp;-1\\
-11&amp;-9&amp;-2&amp;2&amp;0&amp;-1&amp;-1&amp;0\\
-7&amp;-2&amp;0&amp;1&amp;1&amp;0&amp;0&amp;0\\
-1&amp;-1&amp;1&amp;2&amp;0&amp;-1&amp;1&amp;1\\
2&amp;0&amp;2&amp;0&amp;-1&amp;1&amp;1&amp;-1\\
-1&amp;0&amp;0&amp;-1&amp;0&amp;2&amp;1&amp;-1\\
-3&amp;2&amp;-4&amp;-2&amp;2&amp;1&amp;-1&amp;0
\end{bmatrix}
\to
\begin{bmatrix}
79&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0\\
-2&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
-1&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0
\end{bmatrix}
\end{split}\]</div>
</div>
<div class="section" id="encodage-codage-rle-et-codage-de-huffman">
<h3>Encodage - codage RLE et codage de Huffman<a class="headerlink" href="#encodage-codage-rle-et-codage-de-huffman" title="Permalink to this headline">¶</a></h3>
<p>On observe, après quantification, que le nouveau bloc générée contient de nombreux 0 (correspondant aux hautes fréquences) redondants et il va être possible de coder ces informations efficacement.</p>
<p>On va commencer par ordonner les coefficients en suivant un parcours en zigzag à partir du coin supérieur gauche du bloc.</p>
<p><img alt="zigzag" src="../_images/zigzag.png" /></p>
<p>Ce qui nous donne pour l’exemple précédant la suite d’information utile : <em><strong>79 0 -2 -1 -1 -1 0 0 -1</strong></em>où les autres valeurs sont uniquement des zéro.</p>
<p>C’est ici qu’intervient le <strong>codage RLE</strong> basé sur la valeur 0 (le codage RLE intervient uniquement sur cette dernière) et l’information représentant notre bloc donne ici :</p>
<p><strong>79 0 -2 -1 -1 -1 0[2] -1 0[55]</strong></p>
<p>On utilise généralement un caractère particulier pour signifier la fin de la séquence et on peut donc omettre les derniers zéro :</p>
<p><strong>79 0 -2 -1 -1 -1 0[2] -1</strong></p>
<p>Pour finir, on applique aux valeurs précédemment obtenu un <strong>encodage de Huffman</strong>. Il va permettre de donner une correspondance des bits à écrire plus efficace pour constituer notre fichier final.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Compression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../Filtrage/Filtre.html" title="previous page">Filtre</a>
    <a class='right-next' id="next-link" href="../TD/TD1/TP1%20-%20EEA%20-%20Exercices.html" title="next page">TP 1: Analyse en fréquence de signaux sonores.</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By IMAC Students<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>