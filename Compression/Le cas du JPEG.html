
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Le cas du JPEG &#8212; M2 Signal classes</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ondelettes" href="Ondelettes.html" />
    <link rel="prev" title="Compression" href="Compression.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">M2 Signal classes</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Introduction/Introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Fourier
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Transform%C3%A9e%20de%20Fourier/Transform%C3%A9e%20de%20Fourier.html">
   Transformée de Fourier
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Filtrage
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Filtrage/Filtre.html">
   Filtre
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Filtrage/D%C3%A9bruitage.html">
   Débruitage
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Compression
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Compression.html">
   Compression
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Le cas du JPEG
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ondelettes.html">
   Ondelettes
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  TD
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD1/TP1%20-%20EEA%20-%20Exercices.html">
   TD1 - Analyse en fréquence de signaux sonores.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD2/TP2%20-%20FFT%20-%20Exercices.html">
   TD2 - FFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD3/TP3%20-%20Compression%20Shannon-Huffman-Exercises.html">
   TD3 - Compression Shannon-Huffman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD4/TP4%20-%20Spectral%20Analysis%20and%20Filtering-Exercise%20-%20Original.html">
   1. STFT  (Short Time Fourier Transform) and source separation.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD4/TP4%20-%20Spectral%20Analysis%20and%20Filtering-Exercise%20-%20Original.html#the-goal-of-this-part-is-to-explore-implementations-of-a-fir-or-an-iir">
   2. The goal of this part is to explore implementations of a FIR or an IIR.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD4/TP4%20-%20Spectral%20Analysis%20and%20Filtering-Exercise.html">
   TD4 - Spectral Analysis and Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html">
   In this TD, we study the wavelet decomposition using the Daubechies 4 filters.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#what-are-the-conditions-on-the-filters-for-being-admissible-wavelet-filters-the-first-condition-on-the-low-pass-filter-h-is-begin-equation-begin-cases-hat-h-omega-2-hat-h-omega-frac-12-2-2-hat-h-0-sqrt-2-end-cases-end-equation">
   What are the conditions on the filters for being admissible wavelet filters: The first condition on the low-pass filter
   <span class="math notranslate nohighlight">
    \(h\)
   </span>
   is \begin{equation} \begin{cases}|\hat{h}(\omega)|^2 + |\hat{h}(\omega + \frac 12)|^2 = 2\hat{h}(0) = \sqrt{2},.\end{cases}\end{equation}
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#the-condition-on-the-high-pass-filter-is-the-following-begin-equation-begin-cases-hat-g-omega-2-hat-g-omega-frac-12-2-2-hat-g-omega-hat-h-omega-hat-g-omega-frac-12-hat-h-omega-frac-12-0-end-cases-end-equation">
   The condition on the high-pass filter is the following:  \begin{equation} \begin{cases}|\hat{g}(\omega)|^2 + |\hat{g}(\omega + \frac 12)|^2 = 2\hat{g}(\omega) \hat{h}^
   <em>
    (\omega)+ \hat{g}(\omega + \frac 12)\hat{h}^
   </em>
   (\omega + \frac 12) = 0,.\end{cases}\end{equation}
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#q2-implement-below-the-one-step-of-w-transform-of-the-lecture-coarse-and-fine-scale-transforms-and-test-it-on-your-image">
   Q2: Implement below the one step of W transform of the lecture. Coarse and Fine scale transforms and test it on your image.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#q3-implement-the-full-fast-wavelet-transform-for-a-given-number-of-scales">
   Q3: Implement the full fast wavelet transform for a given number of scales.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#q4-below-are-functions-to-obtain-a-better-plot-of-the-results-using-the-functions-below-plot-the-wavelet-transform">
   Q4: Below are functions to obtain a better plot of the results. Using the functions below, plot the wavelet transform.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#q5-the-wavelet-transform-is-an-orthogonal-transformation-so-its-inverse-is-given-by-its-transpose-also-called-adjoint-use-the-two-operators-defined-below-to-implement-the-inverse-of-the-wavelet-transform">
   Q5: The wavelet transform is an orthogonal transformation so its inverse is given by its transpose (also called adjoint). Use the two operators defined below to implement the inverse of the wavelet transform.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#q6-test-on-an-image-that-the-implemented-inverse-is-correct-that-is-check-on-an-image-x-that-iwt-wavelettransform-x-x-up-to-numerical-errors">
   Q6: Test on an image that the implemented inverse is correct. That is, check on an image
   <span class="math notranslate nohighlight">
    \(x\)
   </span>
   that
   <span class="math notranslate nohighlight">
    \(IWT(WaveletTransform(x)) = x\)
   </span>
   up to numerical errors.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-Exercises_original.html#use-of-wavelets-for-compression">
   Use of wavelets for compression.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD5/TP5%20-%20Wavelets%20-%20Exercices.html">
   TD5 - Wavelets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD6/Inverse-Problem.html">
   In this notebook, I give a simple example of an inverse problem which necessitates regularization.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD6/Inverse-Problem.html#remark-noise-in-fourier-is-also-a-noise-you-can-guess-that-the-distribution-of-the-energy-of-the-noise-in-fourier-is-similar-to-its-distribution-in-space">
   Remark: Noise in Fourier is also a noise. You can guess that the distribution of the energy of the noise in Fourier is similar to its distribution in space.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD6/TP6%20-%20Denoising-Exercices_original.html">
   TD6 - Denoising
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD6/TP6%20-%20Denoising-Exercices.html">
   In this TD, we consider simple denoising algorithms, such as the ones considered in the lectures.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization_original.html">
   In this TD, we aim at exploring the gradient descent method for optimizing smooth functions.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization_original.html#a-gradient-descent-in-2d">
   A. Gradient descent in 2D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization_original.html#b-example-on-a-physical-system">
   B. Example on a physical system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization_original.html#we-propose-to-reconstruct-a-candidate-for-our-initial-image-as-the-minimizer-of-an-energy-functional-e-i-sum-i-1-text-nbre-lignes-f-i-i-under-the-constraint-that-i-1-text-mask-text-data">
   We propose to reconstruct a candidate for our initial image as the minimizer of an energy functional
   <span class="math notranslate nohighlight">
    \(E(I) = \sum_{i = 1}^{\text{nbre lignes}} f(I[i,:])\)
   </span>
   under the constraint that
   <span class="math notranslate nohighlight">
    \(I (1-\text{mask}) = \text{data}\)
   </span>
   .
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization.html">
   In this TD, we aim at exploring the gradient descent method for optimizing smooth functions.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization.html#a-gradient-descent-in-2d">
   A. Gradient descent in 2D
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD7/TP7%20-%20Optimization.html#b-example-on-a-physical-system">
   B. Example on a physical system
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD8/TP8%20-%20Non-local%20means-exercises_original.html">
   In this TD, we explore a well-known method for inpainting.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD8/TP8%20-%20Non-local%20means-exercises_original.html#dimensionality-reduction-using-pca-principal-component-analysis">
   2. Dimensionality reduction using PCA: Principal Component Analysis.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD8/TP8%20-%20Non-local%20means-exercises.html">
   In this TD, we explore a well-known method for inpainting.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD8/TP8%20-%20Non-local%20means-exercises.html#dimensionality-reduction-using-pca-principal-component-analysis">
   2. Dimensionality reduction using PCA: Principal Component Analysis.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../TD/TD8/TP8%20-%20Non-local%20means-exercises.html#question-3-explain-what-is-shown-below">
   Question 3: Explain what is shown below ?
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Compression/Le cas du JPEG.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/IMAC-projects/M2-SIS-signal"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/IMAC-projects/M2-SIS-signal/issues/new?title=Issue%20on%20page%20%2FCompression/Le cas du JPEG.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l-image-numerique">
   L’image numérique
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformation-espace-de-couleurs">
   Transformation : espace de couleurs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sous-echantillonnage-de-la-chrominance">
   Sous-échantillonnage de la chrominance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#passage-en-frequence-transformation-en-cosinus-discretes">
   Passage en fréquence : Transformation en cosinus discrètes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantification">
   Quantification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodage-codage-rle-et-codage-de-huffman">
   Encodage - codage RLE et codage de Huffman
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="le-cas-du-jpeg">
<h1>Le cas du JPEG<a class="headerlink" href="#le-cas-du-jpeg" title="Permalink to this headline">¶</a></h1>
<p>Grâce au développement du numérique, les échanges de données, et plus particulièrement des images, sont de plus en plus présent autour de nous.</p>
<p>Le stockage et la rapidité de transmission sont devenus deux enjeux majeurs avec l’émergence de flux de données de plus en plus présent. Il est donc naturel de se demander comment les images sont stockées et transmises.</p>
<p>C’est là qu’intervient la compression et le traitement numérique. Il s’agit en effet de trouver la manière la plus optimisée de représenter les données à l’aide d’algorithmes afin que la représentation compressée soit plus courte que la représentation originale, pour pouvoir ensuite stocker l’information en occupant le moins d’espace et/ou la transmettre rapidement.</p>
<p>Il existe deux grandes familles de compression des données comme vu précédemment : la compression sans pertes qui conserve l’intégralité des informations et la compression avec pertes qui permet d’obtenir de bien meilleurs résultats mais qui altère les données d’origine.</p>
<p>Nous allons donc nous intéresser à la norme de compression JPEG (Joint Photographic Experts Group) qui illustre bien les différentes étapes de compression d’une image et qui fait appel à des processus avec et sans pertes précédemment évoqués.</p>
<div class="section" id="l-image-numerique">
<h2>L’image numérique<a class="headerlink" href="#l-image-numerique" title="Permalink to this headline">¶</a></h2>
<p>De nos jours, les images numériques sont partout, sur nos téléphones, nos ordinateurs et même les affiches publicitaires. Mais bien qu’utilisées de partout, il semble pertinent de revenir rapidement sur ce qu’est réellement une image numérique.</p>
<p>Une image numérique est une représentation <strong>discrète</strong> d’une image classique dit continue obtenue via un convertisseurs analogique-numérique comme une <em>matrice de Bayer</em> par exemple pour la majorité des appareils photos numériques de nos jours. L’idée est de stocker un nombre fini de points codant l’<strong>information lumineuse</strong> (intensité et couleur généralement) représentant l’image.</p>
<p>Dans le cas des images à deux dimensions (le plus courant), elle est représentée par une matrice 2D(ou 3D en fonction du nombre de canal de couleurs) et donc chaque élément est appelés pixels.
La  <strong>définition</strong>  d’une image est définie par le nombre de points composant la matrice. En image numérique, cela correspond au nombre de pixels qui composent l’image en hauteur (axe vertical) et en largeur (axe horizontal) :  exemple 200 pixels par 450 pixels.
La  <strong>résolution</strong>  d’une image est définie par un nombre de pixels par unité de longueur de la structure à numériser. Plus la résolution est élevée, plus le nombre de points est important.</p>
<p>Il existe plusieurs modes de codage pour représenter les couleurs pour chaque pixels, le plus utilisé pour le maniement des images est l’espace colorimétrique rouge, vert, bleu ou <strong>RVB</strong>  ou <strong>RGB</strong> (de l’anglais red-green-blue). Cet espace est basé sur une synthèse additive des couleurs, c’est-à-dire que le mélange des trois composantes R, V, et B à leur valeur maximum donne du blanc, à l’instar de la  lumière. Le mélange de ces trois couleurs à des proportions diverses permet de reproduire à l’écran une part importante du spectre visible, sans avoir à spécifier une multitude de fréquences lumineuses.</p>
<p>Mais il existe d’autres modes de représentation des couleurs appelés <em><strong>espaces colorimétriques</strong></em> (dont nous reparlerons plus tard) :</p>
<ul class="simple">
<li><p><strong>CMJN</strong> (<strong>CMYK</strong>) cyan, magenta, jaune, noir utilisé principalement pour l’impression, et basé sur une  synthèse soustractive des couleurs</p></li>
<li><p><strong>TSL</strong> (<strong>HSL</strong>) pour teinte, saturation, luminance</p></li>
<li><p><strong>YUV</strong> où Y représentant la luminance, U et V deux chrominances</p></li>
</ul>
<p>Ensuite, le codage de la couleur peut être réalisé de différentes manières.</p>
<p>Il peux par exemple être représenter en utilisant trois octets par pixels représentant la valeur d’une composante de couleur par un entier de 0 à 255 (ces trois valeurs codent généralement la couleur dans l’espace <strong>RVB</strong>) , soit qu’un seul octet (8 bits) par pixels si l’image ne représente que l’intensité lumineuse (image en Noir et blanc par exemple).</p>
<p>Avec 8 bits par couleurs, le nombre de couleurs différentes pouvant être ainsi représenté est de 256 × 256 × 256 possibilités, soit environ 16,7 millions de couleurs.</p>
<p>Le nombre de bits utilisés pour représenter la couleurs d’un pixel est appelée la <strong>profondeur de couleurs</strong> et sont l’unité est le bits par pixel (<strong>bpp</strong>).</p>
<p>Une plus grande profondeur de couleurs, ce qui nécessite un plus grand nombre de bits, permet une plus grande échelle de nuances dans les couleurs.</p>
<p>Il existe bien entendu une multitude de  profondeur de couleurs différentes du 16bits en passant par du 32bits mais inutile de rentrer dans le détails ici.</p>
<p>Parfois, une  palette de couleurs appelée look-up table ou LUT peut être utilisée pour stocker une image représentée avec moins de couleurs (256 couleurs) mais nous nous attarderons pas sur ce type de stockage.</p>
</div>
<div class="section" id="transformation-espace-de-couleurs">
<h2>Transformation : espace de couleurs<a class="headerlink" href="#transformation-espace-de-couleurs" title="Permalink to this headline">¶</a></h2>
<p>Il existe plusieurs manières de représenter les couleurs d’une image, soit par les trois composantes <em><strong>Rouge, Vert et Bleu</strong></em> de la synthèse additive d’une couleur (représentation RGB), soit par une représentation circulaire des couleurs où l’on représente trois composantes de <em><strong>teinte</strong></em>, de <em><strong>saturation</strong></em>, et de <em><strong>luminance</strong></em> d’une couleur (représentation TSL). Enfin il est également possible de représenter d’abord la luminance (signal en niveau de gris) et par la suite les deux chrominances, qui représentent chacune une différence de couleur par rapport à la luminance respectivement <strong>U</strong> ou <strong>Cb</strong> pour la différence avec le bleu (B-Y) et <strong>Y</strong> ou Cr pour la différence avec rouge (R - Y). Il est donc possible de passer de RGB a YUV (<strong>YCbCr</strong>) via les calculs suivants:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
	\begin{bmatrix}
	Y \\ U \\ V
	\end{bmatrix}
	=
	\begin{bmatrix}
	0,299 &amp; 0,587 &amp; 0,114\\
	-0,14713 &amp; -0,28886 &amp; 0,436\\
	0,615 &amp; -0,51498 &amp; -0,10001
	\end{bmatrix}
	.
	\begin{bmatrix}
	R \\ G \\ B
	\end{bmatrix}
\end{equation}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
	\begin{bmatrix}
	R \\ G \\ B
	\end{bmatrix}
	=
	\begin{bmatrix}
	1 &amp; 0 &amp; 1,13983 \\
	1 &amp; -0,39465 &amp; -0,58060  \\
	1 &amp; 2,03211 &amp; 0
	\end{bmatrix}
	.
	\begin{bmatrix}
	Y \\ U \\ V
	\end{bmatrix}
\end{equation}
\end{split}\]</div>
<p>L’intérêt d’une telle transformation est que la vision humaine présente une <strong>sensibilité moindre</strong> à la couleur qu’à la luminosité. On va donc pouvoir <strong>sous échantillonner</strong> les composantes de chrominance sans affecter fortement la qualité du rendu final de l’image.</p>
</div>
<div class="section" id="sous-echantillonnage-de-la-chrominance">
<h2>Sous-échantillonnage de la chrominance<a class="headerlink" href="#sous-echantillonnage-de-la-chrominance" title="Permalink to this headline">¶</a></h2>
<p>L’œil humain est beaucoup plus sensible aux variations de lumière qu’à celles de couleur. Ainsi afin de pouvoir permettre un meilleur taux de compression, il est possible de <strong>réduire la répétition</strong> entre les informations de couleurs.</p>
<p>On fait donc appel au <strong>sous-échantillonnage de chrominance</strong>. Cela va donc permettre de réduire la résolution spatiale c’est-à-dire réduire la quantité d’information sur une même surface. On peut ainsi se demander comment cela fonctionne.</p>
<p>Le procédé reste relativement simple. En effet il repose sur la <strong>suppression de paires (Cb;Cr)</strong> ou (U;V) de certains pixels de l’image. Toutefois, il est nécessaire de choisir le mode de sous-échantillonnage parmi ceux utilisés en JPEG : le mode 4:2:0, 4:2:2 ou le mode 4:4:4.</p>
<p>Chaque triplet se décompose ainsi en trois nombres (J : a : ​b) correspondant chacun à une information sur le bloc. On considérera ici un bloc comme étant une région de quatre pixels de largeur sur 2 pixels de hauteur.</p>
<p>Le nombre <strong>J</strong> représente le nombre d’échantillons de luminance par ligne ou encore la largeur du bloc pour le traitement de la chrominance. Ici au vue de la définition que nous avons donnée du bloc on peut ici considérer que J vaut 4.</p>
<p>Le nombre <strong>a</strong> représente le nombre d’échantillons de chrominance (Cb, Cr) dans la première ligne tandis que b représente celui de la deuxième ligne.</p>
<p><img alt="Subsampling modes" src="../_images/subSampling.png" /></p>
<p>Ainsi, en s’intéressant de plus près au schéma, on peut voir l’évolution du bloc, selon les différents modes de sous échantillonnage appliqués.</p>
<ul class="simple">
<li><p>On peut donc voir qu’en commençant par la gauche, le premier mode 4:4:4 correspond au mode où aucune altération n’a été réalisée. Nous sommes donc dans le cas de notre image d’origine. Chaque case possède bien une information de luminance (carré gris Y) ainsi que les deux informations de chrominances (triangles bleu Cb et rouge Cr).</p></li>
<li><p>Dans le second mode 4:2:2, les informations de luminances sont conservées, mais on ne conserve que deux couples d’informations de chrominance sur les quatre de chaque ligne. Les deux composantes de chrominance sont donc échantillonnées à la moitié de la fréquence d’échantillonnage de luminance. Les pixels ne contenant pas d’informations de chrominances sont affichés lors du décodage avec une moyenne des valeurs gauche et droite.</p></li>
<li><p>Dans le troisième mode <strong>4:2:0</strong>, seules deux des couples d’informations de chrominances de la première ligne sont conservées. Pour retrouver les informations perdues, on procédera de la même manière que dans le mode précédent en moyennant les valeurs manquantes lors du décodage.</p></li>
<li><p>Le dernier mode <strong>4:1:1</strong> est peu utilisée voire jamais dans le cas du JPEG.</p></li>
</ul>
<p>Grâce à cette méthode, le nombre d’échantillons contenu dans l’image diminuant, le volume de l’image traitée diminue aussi permettant donc d’obtenir une image moins conséquente en terme de taille sans pour autant la dégrader de façon trop visible pour l’œil humain.</p>
</div>
<div class="section" id="passage-en-frequence-transformation-en-cosinus-discretes">
<h2>Passage en fréquence : Transformation en cosinus discrètes<a class="headerlink" href="#passage-en-frequence-transformation-en-cosinus-discretes" title="Permalink to this headline">¶</a></h2>
<p>Jusqu’à présent, on a juste transformé le mode de couleur en <strong>YUV</strong> ou <strong>YCbCr</strong> et appliqué un sous-échantillonnage sur les composantes de la chrominance. Nous allons à présent appliquer la DCT à l’image.</p>
<p>Considérons ici par simplicité pour les explications une unique couche, la luminance.</p>
<p>A l’image d’une transformée de Fourier, il est possible d’appliquer une <strong>transformée en cosinus discrète TCD ou DCT</strong> à un signal/image. Cela permet de représenter l’image sous forme de “fréquences”.</p>
<p>La DCT et en particulier la DCT-II est très utilisée en traitement du signal. L’intérêt d’une telle transformation en fréquence se voit particulièrement bien sûr l’image suivante (un échantillon de taille 8x8 de notre image) :</p>
<p><img alt="DCT coefficients" src="../_images/DCTonBlock8x8.png" /></p>
<p>A gauche un bloc de notre image et à droite le calcul des coefficients de la DCT-II . On voit clairement ici que les coefficients de grande importance pour reconstituer l’image se concentrent en haut à gauche (les coefficients dit de <em>basses fréquences</em>).</p>
<p>L’idée de la compression par DCT est de conserver uniquement les quelques coefficients important (basses fréquences) non nuls utiles pour reconstruire la majorité de l’image et annuler les autres petites valeurs par quantification (c’est une opération analogue à l’application d’un filtre passe bas).</p>
<p>La DCT-II s’applique en 2D via la formule suivante : (sur un bloc de taille <span class="math notranslate nohighlight">\(M\times N\)</span>)</p>
<div class="math notranslate nohighlight">
\[
DCT[i, j] = \frac{2}{\sqrt{MN}} C(i)C(j)\sum^{N-1}_{x=0}\sum^{M-1}_{y=0} pixel[x, y].cos(\frac{\pi i}{2N}.(2x+1)).cos(\frac{\pi j}{2M}.(2y+1))
\]</div>
<p>avec :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
C(x) = \left\{
\begin{array}{rl}
\frac{1}{\sqrt{2}} &amp; \text{si } x = 0  \\ 
1 &amp; \text{sinon} \\
\end{array}
\right.
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\frac{2}{\sqrt{MN}}\)</span> , <span class="math notranslate nohighlight">\(C(i)\)</span> et <span class="math notranslate nohighlight">\(C(j)\)</span> sont des facteurs qui permettent de rendre la transformation orthogonale car cette forme normalisée est très utilisée en pratique.</p>
<p>L’application de la DCT est une opération <strong>théoriquement sans perte d’informations</strong> ; les coefficients initiaux peuvent être retrouvés en appliquant la « DCT inverse » au résultat de la DCT. Dans la pratique, une certaine perte d’informations reste cependant possible en raison des erreurs d’arrondis introduites en cours de calcul.</p>
<hr class="docutils" />
<p>À chaque bloc de <span class="math notranslate nohighlight">\(N \times N\)</span> pixels sont ainsi associés <span class="math notranslate nohighlight">\(N \times N\)</span> fréquences.</p>
<p>Celle-ci est appliquée sur les deux axes de l’image 2D, ci-dessous une représentation des différentes fréquences ainsi obtenue sur les deux axes.</p>
<p><img alt="Représentation des fréquences" src="../_images/DCT.jpg" /></p>
</div>
<div class="section" id="quantification">
<h2>Quantification<a class="headerlink" href="#quantification" title="Permalink to this headline">¶</a></h2>
<p>L’œil humain distingue difficilement les zones de hautes fréquences, il est donc envisageable de <strong>réduire l’importance de ces zones de hautes fréquences</strong> sur l’image considérée.</p>
<p>Ainsi cette opération permettra également de réduire la place mémoire nécessaire pour le stockage de l’image en question.</p>
<p>Le principe de la quantification est relativement simple.</p>
<p>Cela repose sur une division de chaque coefficient de la matrice DCT obtenue par une constante afin de réduire le nombre d’entiers utilisés pour chaque valeur. La valeur de la constante va dépendre de l’endroit où se trouve les coefficients et l’on va donc réaliser une division de la matrice obtenue après DCT par une nouvelle matrice dite  <strong>de quantification</strong> .</p>
<p>Les basses fréquences étant représentées par les coefficients situés dans le coin haut gauche de la matrice de coefficients de la DTC et l’œil humain étant plus sensible à ces fréquences-ci, les coefficients de la matrice de quantification seront plus faibles dans cette zone afin de pouvoir mieux <strong>conserver les informations importantes pour notre système visuel</strong>.</p>
<p>Exemple de matrice de quantification :
$<span class="math notranslate nohighlight">\(
\begin{bmatrix}
3&amp;5&amp;7&amp;9&amp;11&amp;13&amp;15&amp;17\\
5&amp;7&amp;9&amp;11&amp;13&amp;15&amp;17&amp;19\\
7&amp;9&amp;11&amp;13&amp;15&amp;17&amp;19&amp;21\\
9&amp;11&amp;13&amp;15&amp;17&amp;19&amp;21&amp;23\\
11&amp;13&amp;15&amp;17&amp;19&amp;21&amp;23&amp;25\\
13&amp;15&amp;17&amp;19&amp;21&amp;23&amp;25&amp;27\\
15&amp;17&amp;19&amp;21&amp;23&amp;25&amp;27&amp;29\\
17&amp;19&amp;21&amp;23&amp;25&amp;27&amp;29&amp;31
\end{bmatrix}
\)</span>$</p>
<blockquote>
<div><p>Les coefficients les plus fort correspondent aux hautes fréquences</p>
</div></blockquote>
<p>Après division, il suffit de prendre l’arrondis des coefficients qui seront pour la plupart nuls. On <strong>élimine ainsi les informations de faible importance</strong> pour notre vision. C’est donc à cette étape-ci qu’il y a <strong>pertes ou destruction d’informations par rapport à l’image originale</strong> et c’est pour cette raison que l’on qualifie la compression JPEG d’irréversible et destructive.</p>
<p>Voilà le résultat de cette étape de quantification : une image complète appliquée par blocs de <span class="math notranslate nohighlight">\(8 \times 8\)</span>
<img alt="blockwise DCT quantization" src="../_images/DCTQuantization.png" /></p>
<p>Et voici un exemple plus spécifiquement sur un bloc particulier avant et après quantification :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
1260&amp;-1&amp;-12&amp;-5&amp;2&amp;-2&amp;-3&amp;1\\
-23&amp;-17&amp;-6&amp;-3&amp;-3&amp;0&amp;0&amp;-1\\
-11&amp;-9&amp;-2&amp;2&amp;0&amp;-1&amp;-1&amp;0\\
-7&amp;-2&amp;0&amp;1&amp;1&amp;0&amp;0&amp;0\\
-1&amp;-1&amp;1&amp;2&amp;0&amp;-1&amp;1&amp;1\\
2&amp;0&amp;2&amp;0&amp;-1&amp;1&amp;1&amp;-1\\
-1&amp;0&amp;0&amp;-1&amp;0&amp;2&amp;1&amp;-1\\
-3&amp;2&amp;-4&amp;-2&amp;2&amp;1&amp;-1&amp;0
\end{bmatrix}
\to
\begin{bmatrix}
79&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0\\
-2&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
-1&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0
\end{bmatrix}
\end{split}\]</div>
</div>
<div class="section" id="encodage-codage-rle-et-codage-de-huffman">
<h2>Encodage - codage RLE et codage de Huffman<a class="headerlink" href="#encodage-codage-rle-et-codage-de-huffman" title="Permalink to this headline">¶</a></h2>
<p>On observe, après quantification, que le nouveau bloc générée contient de nombreux 0 (correspondant aux hautes fréquences) redondants et il va être possible de coder ces informations efficacement.</p>
<p>On va commencer par ordonner les coefficients en suivant un parcours en zigzag à partir du coin supérieur gauche du bloc.</p>
<p><img alt="zigzag" src="../_images/zigzag.png" /></p>
<p>Ce qui nous donne pour l’exemple précédant la suite d’information utile : <em><strong>79 0 -2 -1 -1 -1 0 0 -1</strong></em> où les autres valeurs sont uniquement des zéro.</p>
<p>C’est ici qu’intervient le <strong>codage RLE</strong> basé sur la valeur 0 (le codage RLE intervient uniquement sur cette dernière) et l’information représentant notre bloc donne ici :</p>
<p><strong>79 0 -2 -1 -1 -1 0[2] -1 0[55]</strong></p>
<p>On utilise généralement un caractère particulier pour signifier la fin de la séquence et on peut donc omettre les derniers zéro :</p>
<p><strong>79 0 -2 -1 -1 -1 0[2] -1</strong></p>
<p>Pour finir, on applique aux valeurs précédemment obtenu un <strong>encodage de Huffman</strong>. Il va permettre de donner une correspondance des bits à écrire plus efficace pour constituer notre fichier final.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Compression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Compression.html" title="previous page">Compression</a>
    <a class='right-next' id="next-link" href="Ondelettes.html" title="next page">Ondelettes</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By IMAC Students<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>